{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not looking at your data\n",
    "\n",
    "> There  is  a  growing  realization  that  statistically  significant  claims  in  scientific  publications  are\n",
    "routinely mistaken.  A dataset can be analyzed in so many different ways (with the choices being\n",
    "not just what statistical test to perform but also decisions on what data to exclude or exclude, what\n",
    "measures to study, what interactions to consider, etc.), that very little information is provided by\n",
    "the statement that a study came up with a p < .05 result. The short version is that it’s easy to find a\n",
    "p < . 05 comparison even if nothing is going on, if you look hard enough—and good scientists\n",
    "are skilled at looking hard enough and subsequently coming up with good stories (plausible even to\n",
    "themselves, as well as to their colleagues and peer reviewers) to back up any statistically-significant\n",
    "comparisons they happen to come up with.\n",
    "\n",
    "[A. Gelman and E. Loken, *The garden of forking paths:  Why multiple comparisons can be a problem,\n",
    "even when there is no “fishing expedition” or “p-hacking” and the research\n",
    "hypothesis was posited ahead of time*](http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf)\n",
    "\n",
    "\n",
    "Having a model that fits the data is not enough if it has no predictive power. Consequently, it is never enough to test your model on the data used to build it.\n",
    "\n",
    "## The simple way to test your model\n",
    "\n",
    "Gather new data and test your model on it. Note that you're still not completely safe from falling into questionable research practices (and resulting bad statistics); Fix every step before seeing the data, if possible!\n",
    "\n",
    "But that's not always practical, so what can you do instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data\n",
    "\n",
    "Often used when new data is difficult to collect, and especially common with machine learning.\n",
    "\n",
    "**The idea:** \n",
    "Separate the dataset randomly to multiple independent datasets:\n",
    "\n",
    "- Development data\n",
    "    * Used to select and create the model\n",
    "    \n",
    "- Test data\n",
    "    * Used to test the model on unseen data after the parameters have been selected. \n",
    "    * **Once you touch this, you are done!**\n",
    "    \n",
    "Usually the development dataset is further split into *training* and *validation* datasets in some way in order to prevent *overfitting* to the data. The model is then fit with the training set, and error on the validation set is used  to see whether the model generalizes to the rest of the data.\n",
    "\n",
    "**Note:**\n",
    ">Some texts/software will refer to the development data as training data, and may not be very clear on the difference between validation and test data. Be vigilant and know the reason every time you split your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "To further reduce the danger of overfitting, the splitting/fitting procedure can be repeated multiple times on the development dataset, with the errors on the different validation sets used to determine model quality. Different types of cross-validation methods can be used depending on the constraints of the application:\n",
    "\n",
    "*Exhaustive:*\n",
    "- Leave-p-out (Remove each set of p samples in turn from the training set)\n",
    "    * Special case: Leave-one-out\n",
    "    * Time- and computation-wise usually very expensive\n",
    "    \n",
    "*Non-exhaustive*\n",
    "- k-fold (randomly split into k subsets using each as validation set in turn, with the k-1 others as training)\n",
    "- repeated random sampling\n",
    "\n",
    "**Q:**\n",
    "> Random splitting isn't always appropriate. What cases can you think of?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
