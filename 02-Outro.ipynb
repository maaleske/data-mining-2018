{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Not looking at your data\n",
    "\n",
    "> There  is  a  growing  realization  that  statistically  significant  claims  in  scientific  publications  are\n",
    "routinely mistaken.  A dataset can be analyzed in so many different ways (with the choices being\n",
    "not just what statistical test to perform but also decisions on what data to exclude or exclude, what\n",
    "measures to study, what interactions to consider, etc.), that very little information is provided by\n",
    "the statement that a study came up with a p < .05 result. The short version is that it’s easy to find a\n",
    "p < . 05 comparison even if nothing is going on, if you look hard enough—and good scientists\n",
    "are skilled at looking hard enough and subsequently coming up with good stories (plausible even to\n",
    "themselves, as well as to their colleagues and peer reviewers) to back up any statistically-significant\n",
    "comparisons they happen to come up with.\n",
    "\n",
    "[A. Gelman and E. Loken, *The garden of forking paths:  Why multiple comparisons can be a problem,\n",
    "even when there is no “fishing expedition” or “p-hacking” and the research\n",
    "hypothesis was posited ahead of time*](http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf)\n",
    "\n",
    "\n",
    "Having a model that fits the data is not enough if it has no predictive power. Consequently, it is never enough to test your model on the data used to build it.\n",
    "\n",
    "## The simple way to test your model\n",
    "\n",
    "Gather new data and test your model on it. Note that you're still not completely safe from falling into questionable research practices (and resulting bad statistics); Fix every step before seeing the data, if possible!\n",
    "\n",
    "But that's not always practical, so what can you do instead?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting data\n",
    "\n",
    "Often used when new data is difficult to collect, and especially common with machine learning.\n",
    "\n",
    "**The idea:** \n",
    "Separate the dataset randomly to multiple independent datasets:\n",
    "\n",
    "- Development data\n",
    "    * Used to select and create the model\n",
    "    \n",
    "- Test data\n",
    "    * Used to test the model on unseen data after the parameters have been selected. \n",
    "    * **Once you touch this, you are done!**\n",
    "    \n",
    "Usually the development dataset is further split into *training* and *validation* datasets in some way in order to prevent *overfitting* to the data. The model is then fit with the training set, and error on the validation set is used  to see whether the model generalizes to the rest of the data.\n",
    "\n",
    "**Note:**\n",
    ">Some texts/software will refer to the development data as training data, and may not be very clear on the difference between validation and test data. Be vigilant and know the reason every time you split your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-validation\n",
    "\n",
    "To further reduce the danger of overfitting, the splitting/fitting procedure can be repeated multiple times on the development dataset, with the errors on the different validation sets used to determine model quality. Different types of cross-validation methods can be used depending on the constraints of the application:\n",
    "\n",
    "*Exhaustive:*\n",
    "- Leave-p-out (Remove each set of p samples in turn from the training set)\n",
    "    * Special case: Leave-one-out\n",
    "    * Time- and computation-wise usually very expensive\n",
    "    \n",
    "*Non-exhaustive*\n",
    "- k-fold (randomly split into k subsets using each as validation set in turn, with the k-1 others as training)\n",
    "- repeated random sampling\n",
    "\n",
    "**Q:**\n",
    "> Random splitting isn't always appropriate. What cases can you think of?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other considerations and things to look out for\n",
    "\n",
    "## Parsing\n",
    "\n",
    "Data tends to come in many formats (both syntax and file formats), which all have their idiosyncracies. Some common pitfalls to look out for:\n",
    "\n",
    "- Date formats (DD/MM/YY vs MM/DD/YY vs YYYY/MM/DD vs ...)\n",
    "- Comma vs. period as decimal separator\n",
    "- Non-latin characters\n",
    "- Alphabetic ordering (or lack of it)\n",
    "- Automatic parsing to the wrong type. Can and will result in hard-to-debug arithmetic errors, when e.g. dates are interpreted as values or vice versa (Excel has been infamous for this: 2018-02-16 = 2000)\n",
    "- Categorical values considered continuous\n",
    "\n",
    "## Missing values\n",
    "\n",
    "Samples do not always contain all the variables. In the case of the previous Windermere dataset, if we were to consider each day a separate sample, not all variables would have been measured for each day.\n",
    "\n",
    "Different approaches of dealing with these are:\n",
    "\n",
    "- Choosing a method that can operate without all the values (e.g. decision trees)\n",
    "- Imputation, i.e. filling in the missing values based on the other variables & domain knowledge\n",
    "- Discard samples with missing data\n",
    "\n",
    "Consult your local statistician before to make sure the given treatment is appropriate.\n",
    "\n",
    "## Scaling and encoding\n",
    "\n",
    "Many machine learning methods expect data to be in certain ranges, or do not function well with dissimilar ranges of different variables, which may necessitate numerical scaling or offsetting of numerical variables. Categorical data may also need to be numerically encoded depending on the software used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A puzzle\n",
    "\n",
    "<img src=\"./worms.png\" title=\"Worms on a scanner bed\">\n",
    "**Q:**\n",
    "> You have a bunch of worms and your goal is to determine their total biomass from the given picture. How do you proceed?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
